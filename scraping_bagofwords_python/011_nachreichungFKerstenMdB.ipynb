{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9002a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snscrape in /home/fw/anaconda3/lib/python3.9/site-packages (0.6.1.20230314)\n",
      "Collecting snscrape\n",
      "  Downloading snscrape-0.7.0.20230622-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lxml in /home/fw/anaconda3/lib/python3.9/site-packages (from snscrape) (4.9.1)\n",
      "Requirement already satisfied: filelock in /home/fw/anaconda3/lib/python3.9/site-packages (from snscrape) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /home/fw/anaconda3/lib/python3.9/site-packages (from snscrape) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/fw/anaconda3/lib/python3.9/site-packages (from snscrape) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/fw/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->snscrape) (2.3.2.post1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/fw/anaconda3/lib/python3.9/site-packages (from requests[socks]->snscrape) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/fw/anaconda3/lib/python3.9/site-packages (from requests[socks]->snscrape) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/fw/anaconda3/lib/python3.9/site-packages (from requests[socks]->snscrape) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/fw/anaconda3/lib/python3.9/site-packages (from requests[socks]->snscrape) (2.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/fw/anaconda3/lib/python3.9/site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Installing collected packages: snscrape\n",
      "  Attempting uninstall: snscrape\n",
      "    Found existing installation: snscrape 0.6.1.20230314\n",
      "    Uninstalling snscrape-0.6.1.20230314:\n",
      "      Successfully uninstalled snscrape-0.6.1.20230314\n",
      "Successfully installed snscrape-0.7.0.20230622\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85dc7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basis packages\n",
    "import requests\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sea\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "from time import sleep\n",
    "\n",
    "# scrape packages: snscrape\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7162ae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/25000 [00:00<?, ?it/s]Error retrieving https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22from%3AFKerstenMdB%20since%3A2022-01-01%20until%3A2022-11-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D: blocked (404)\n",
      "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22from%3AFKerstenMdB%20since%3A2022-01-01%20until%3A2022-11-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.\n",
      "Errors: blocked (404), blocked (404), blocked (404), blocked (404)\n",
      "  0%|                                                 | 0/25000 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22from%3AFKerstenMdB%20since%3A2022-01-01%20until%3A2022-11-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m tweets_zwischen \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(namen):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# tqdm hier: anzeige der bisher durchgeführten iterationen des codes;\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# total=maximum+1 verwandelt das in progress bar mit 15001=100%\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(sntwitter\u001b[38;5;241m.\u001b[39mTwitterSearchScraper(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m since:2022-01-01 until:2022-11-01\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(namen[n]))\u001b[38;5;241m.\u001b[39mget_items(), total\u001b[38;5;241m=\u001b[39mmaximum)):\n\u001b[1;32m     13\u001b[0m         \n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# break bedingung bei maximum an tweets/person festsetzen (evtl. ratsam bei riesigen mengen)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m#if i>maximum:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m#    break\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         \n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# für die anzahl tweets pro einzelscraping\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         tweets_zwischen\u001b[38;5;241m.\u001b[39mappend([tweet\u001b[38;5;241m.\u001b[39mdate, tweet\u001b[38;5;241m.\u001b[39mid, tweet\u001b[38;5;241m.\u001b[39mrawContent,\n\u001b[1;32m     20\u001b[0m                                 tweet\u001b[38;5;241m.\u001b[39mreplyCount, tweet\u001b[38;5;241m.\u001b[39mretweetCount, tweet\u001b[38;5;241m.\u001b[39mlikeCount, tweet\u001b[38;5;241m.\u001b[39mquoteCount,\n\u001b[1;32m     21\u001b[0m                                 tweet\u001b[38;5;241m.\u001b[39mmedia, tweet\u001b[38;5;241m.\u001b[39mretweetedTweet, tweet\u001b[38;5;241m.\u001b[39mquotedTweet,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m                                 tweet\u001b[38;5;241m.\u001b[39muser\u001b[38;5;241m.\u001b[39musername, tweet\u001b[38;5;241m.\u001b[39muser\u001b[38;5;241m.\u001b[39mid, tweet\u001b[38;5;241m.\u001b[39muser\u001b[38;5;241m.\u001b[39mlocation,\n\u001b[1;32m     25\u001b[0m                                 tweet\u001b[38;5;241m.\u001b[39muser\u001b[38;5;241m.\u001b[39mfollowersCount])\n\u001b[1;32m     26\u001b[0m         tweets_zwischenlauf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(tweets_zwischen, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdateTime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweetID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m                                                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplies\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretweets\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlikes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquotes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m                                                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedia\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misRetweeted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misQuoted\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m                                                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepliedTo_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepliedTo_user\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmentionedUsers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m                                                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoords\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweetLoc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashtagList\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcashtags\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m                                                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserLoc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowerAmount\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/snscrape/modules/twitter.py:1763\u001b[0m, in \u001b[0;36mTwitterSearchScraper.get_items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m: variables, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m: features}\n\u001b[1;32m   1761\u001b[0m paginationParams \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m: paginationVariables, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m: features}\n\u001b[0;32m-> 1763\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_api_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline\u001b[39m\u001b[38;5;124m'\u001b[39m, _TwitterAPIType\u001b[38;5;241m.\u001b[39mGRAPHQL, params, paginationParams, cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor, instructionsPath \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_by_raw_query\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_timeline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m   1764\u001b[0m \t\u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphql_timeline_instructions_to_tweets(obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_by_raw_query\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_timeline\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeline\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/snscrape/modules/twitter.py:915\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._iter_api_data\u001b[0;34m(self, endpoint, apiType, params, paginationParams, cursor, direction, instructionsPath)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieving scroll page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcursor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 915\u001b[0m \tobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_api_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapiType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreqParams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \t\u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    918\u001b[0m \t\u001b[38;5;66;03m# No data format test, just a hard and loud crash if anything's wrong :-)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/snscrape/modules/twitter.py:886\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._get_api_data\u001b[0;34m(self, endpoint, apiType, params, instructionsPath)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apiType \u001b[38;5;129;01mis\u001b[39;00m _TwitterAPIType\u001b[38;5;241m.\u001b[39mGRAPHQL:\n\u001b[1;32m    885\u001b[0m \tparams \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murlencode({k: json\u001b[38;5;241m.\u001b[39mdumps(v, separators \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems()}, quote_via \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39mquote)\n\u001b[0;32m--> 886\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apiHeaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponseOkCallback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_api_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapiType\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mapiType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39m_snscrapeObj\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/snscrape/base.py:275\u001b[0m, in \u001b[0;36mScraper._get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 275\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/snscrape/base.py:271\u001b[0m, in \u001b[0;36mScraper._request\u001b[0;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[1;32m    269\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39mfatal(msg)\n\u001b[1;32m    270\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39mfatal(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mErrors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(errors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 271\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m ScraperException(msg)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReached unreachable code\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mScraperException\u001b[0m: 4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22from%3AFKerstenMdB%20since%3A2022-01-01%20until%3A2022-11-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up."
     ]
    }
   ],
   "source": [
    "# namen immer einzeln neu einsetzen, da sonst fehler mit neuer Twitter API\n",
    "namen = ['FKerstenMdB']\n",
    "maximum = 25000\n",
    "#pbar = tqdm(total=counter)\n",
    "\n",
    "# jedes mal überschreiben bitte!\n",
    "tweets_zwischen = []\n",
    "\n",
    "for n, k in enumerate(namen):\n",
    "    # tqdm hier: anzeige der bisher durchgeführten iterationen des codes;\n",
    "    # total=maximum+1 verwandelt das in progress bar mit 15001=100%\n",
    "    for i, tweet in enumerate(tqdm(sntwitter.TwitterSearchScraper('from:{} since:2022-01-01 until:2022-11-01'.format(namen[n])).get_items(), total=maximum)):\n",
    "        \n",
    "        # break bedingung bei maximum an tweets/person festsetzen (evtl. ratsam bei riesigen mengen)\n",
    "        #if i>maximum:\n",
    "        #    break\n",
    "        \n",
    "        # für die anzahl tweets pro einzelscraping\n",
    "        tweets_zwischen.append([tweet.date, tweet.id, tweet.rawContent,\n",
    "                                tweet.replyCount, tweet.retweetCount, tweet.likeCount, tweet.quoteCount,\n",
    "                                tweet.media, tweet.retweetedTweet, tweet.quotedTweet,\n",
    "                                tweet.inReplyToTweetId, tweet.inReplyToUser, tweet.mentionedUsers,\n",
    "                                tweet.coordinates, tweet.place, tweet.hashtags, tweet.cashtags,\n",
    "                                tweet.user.username, tweet.user.id, tweet.user.location,\n",
    "                                tweet.user.followersCount])\n",
    "        tweets_zwischenlauf = pd.DataFrame(tweets_zwischen, columns = [\"dateTime\", \"tweetID\", \"content\",\n",
    "                                                            \"replies\", \"retweets\", \"likes\", \"quotes\",\n",
    "                                                            \"media\", \"isRetweeted\", \"isQuoted\",\n",
    "                                                            \"repliedTo_ID\", \"repliedTo_user\", \"mentionedUsers\",\n",
    "                                                            \"coords\", \"tweetLoc\", \"hashtagList\", \"cashtags\",\n",
    "                                                            \"user\", \"userID\", \"userLoc\", \"followerAmount\"])\n",
    "        \n",
    "        # welche attribute für gesamtdaten abgegriffen werden\n",
    "        tweets_medien.append([tweet.date, tweet.id, tweet.rawContent,\n",
    "                                tweet.replyCount, tweet.retweetCount, tweet.likeCount, tweet.quoteCount,\n",
    "                                tweet.media, tweet.retweetedTweet, tweet.quotedTweet,\n",
    "                                tweet.inReplyToTweetId, tweet.inReplyToUser, tweet.mentionedUsers,\n",
    "                                tweet.coordinates, tweet.place, tweet.hashtags, tweet.cashtags,\n",
    "                                tweet.user.username, tweet.user.id, tweet.user.location,\n",
    "                                tweet.user.followersCount])\n",
    "\n",
    "        # gleich in dataframe umwandeln\n",
    "        kersten = pd.DataFrame(tweets_medien, columns = [\"dateTime\", \"tweetID\", \"content\",\n",
    "                                                            \"replies\", \"retweets\", \"likes\", \"quotes\",\n",
    "                                                            \"media\", \"isRetweeted\", \"isQuoted\",\n",
    "                                                            \"repliedTo_ID\", \"repliedTo_user\", \"mentionedUsers\",\n",
    "                                                            \"coords\", \"tweetLoc\", \"hashtagList\", \"cashtags\",\n",
    "                                                            \"user\", \"userID\", \"userLoc\", \"followerAmount\"])\n",
    "        \n",
    "# ausgabe zusätzlicher statistik am ende des scrapings: anz. insgesamter tweets nach scraping\n",
    "# + tweets des scraping durchgangs\n",
    "num_tweets_scrape = tweets_zwischenlauf.shape[0]\n",
    "num_tweets_all = medientweets.shape[0]\n",
    "#print(counter)\n",
    "print(f'Anzahl der Tweets in diesem Durchgang: {num_tweets_scrape} Tweets.')\n",
    "print(f'Insgesamt befinden sich im Datensatz: {num_tweets_all} Tweets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
